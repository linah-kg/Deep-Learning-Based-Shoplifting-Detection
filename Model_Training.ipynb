{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+qTWLxrKiFlkbv2k+VvpM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/linah-kg/Deep-Learning-Based-Shoplifting-Detection/blob/main/Model_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.applications import MobileNetV3Small\n",
        "from tensorflow.keras.layers import GRU, Dense, BatchNormalization, Flatten, TimeDistributed, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc\n",
        "import time\n",
        "import pickle\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n"
      ],
      "metadata": {
        "id": "ZXPqaAqO68ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQUENCE_LENGTH = 30\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_path = '/content/drive/My Drive/Shoplifting-Datasets/processed_data_no_augmentation_splited801010'\n",
        "\n",
        "def load_data(file_name):\n",
        "    with open(file_name, 'rb') as file:\n",
        "        return pickle.load(file)\n",
        "\n",
        "# Load the data\n",
        "train_data = load_data(os.path.join(data_path, f'train_data_{SEQUENCE_LENGTH}.pkl'))\n",
        "val_data = load_data(os.path.join(data_path, f'val_data_{SEQUENCE_LENGTH}.pkl'))\n",
        "test_data = load_data(os.path.join(data_path, f'test_data_{SEQUENCE_LENGTH}.pkl'))\n",
        "\n",
        "# Unpack the datasets\n",
        "X_train, y_train = train_data\n",
        "X_val, y_val = val_data\n",
        "X_test, y_test = test_data\n",
        "\n",
        "print(\"Data loaded successfully!\")"
      ],
      "metadata": {
        "id": "7M1hD7fn7DHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 2\n",
        "# Ensure labels are in one-hot encoded format\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_val = to_categorical(y_val, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_val shape: {y_val.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "tBLCQmhZ7Hw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbStPubc647x"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.layers import (Input, GRU, Bidirectional, Dense, Concatenate,\n",
        "                                     TimeDistributed, Dropout, BatchNormalization,\n",
        "                                     GlobalAveragePooling2D, Reshape, Multiply, Softmax)\n",
        "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.saving import register_keras_serializable\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "\n",
        "frame_shape = (224, 224, 3)\n",
        "num_frames = 30\n",
        "input_shape = (num_frames, 224, 224, 3)\n",
        "\n",
        "\n",
        "def FeatureAttention(x):\n",
        "    squeeze = TimeDistributed(GlobalAveragePooling2D())(x)\n",
        "    excitation = Dense(units=squeeze.shape[-1] // 16, activation='relu')(squeeze)\n",
        "    excitation = Dense(units=squeeze.shape[-1], activation='sigmoid')(excitation)\n",
        "    excitation = TimeDistributed(Reshape((1, 1, -1)))(excitation)\n",
        "    return Multiply()([x, excitation])\n",
        "\n",
        "@register_keras_serializable()\n",
        "class TemporalAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(TemporalAttention, self).__init__(**kwargs)\n",
        "        self.dense = Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        score = tf.nn.tanh(self.dense(inputs))\n",
        "        attention_weights = Softmax(axis=1)(score)\n",
        "        context_vector = attention_weights * inputs\n",
        "        return tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(TemporalAttention, self).get_config()\n",
        "        return config\n",
        "\n",
        "# Input Layer\n",
        "input_layer = Input(shape=input_shape)\n",
        "\n",
        "# Feature Extractors: Two parallel light CNNs\n",
        "mobilenet = MobileNetV2(weights='imagenet', include_top=False, input_shape=frame_shape)\n",
        "efficientnet = EfficientNetB0(weights='imagenet', include_top=False, input_shape=frame_shape)\n",
        "\n",
        "# Freeze all layers and unfreeze the last 40 layers for fine-tuning\n",
        "mobilenet.trainable = False\n",
        "efficientnet.trainable = False\n",
        "for layer in mobilenet.layers[-40:]:\n",
        "    layer.trainable = True\n",
        "for layer in efficientnet.layers[-40:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Apply CNNs to each frame using TimeDistributed\n",
        "mobilenet_out = TimeDistributed(mobilenet)(input_layer)\n",
        "efficientnet_out = TimeDistributed(efficientnet)(input_layer)\n",
        "\n",
        "# Apply Feature Attention\n",
        "mobilenet_out = FeatureAttention(mobilenet_out)\n",
        "efficientnet_out = FeatureAttention(efficientnet_out)\n",
        "\n",
        "# Global Average Pooling and feature concatenation\n",
        "mobilenet_out = TimeDistributed(GlobalAveragePooling2D())(mobilenet_out)\n",
        "efficientnet_out = TimeDistributed(GlobalAveragePooling2D())(efficientnet_out)\n",
        "merged_features = Concatenate()([mobilenet_out, efficientnet_out])\n",
        "\n",
        "# Temporal modeling with Two stacked Bidirectional GRU layers\n",
        "gru_out1 = Bidirectional(GRU(256, return_sequences=True))(merged_features)\n",
        "gru_out1 = Dropout(0.3)(gru_out1)\n",
        "gru_out2 = Bidirectional(GRU(256, return_sequences=True))(gru_out1)\n",
        "gru_out2 = TemporalAttention()(gru_out2)\n",
        "\n",
        "# Fully Connected Layers with BatchNorm & Dropout\n",
        "dense1 = Dense(512, activation='relu')(gru_out2)\n",
        "dense1 = BatchNormalization()(dense1)\n",
        "dense1 = Dropout(0.3)(dense1)\n",
        "dense2 = Dense(256, activation='relu')(dense1)\n",
        "dense2 = BatchNormalization()(dense2)\n",
        "dense2 = Dropout(0.3)(dense2)\n",
        "dense3 = Dense(128, activation='relu')(dense2)\n",
        "dense3 = BatchNormalization()(dense3)\n",
        "dense3 = Dropout(0.3)(dense3)\n",
        "\n",
        "# Final output layer\n",
        "output_layer = Dense(2, activation='softmax', dtype='float32')(dense3)\n",
        "\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "filepath = '/content/drive/My Drive/Shoplifting-Datasets/Best-Models/PrallelCNN-MobileNetV2-EfficientNetB0-2BiGRU_model_epoch_{epoch:02d}_val_acc_{val_accuracy:.2f}.keras'\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=filepath,\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=20,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=8, validation_data=(X_val, y_val), callbacks=[checkpoint_callback, early_stopping])\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "precision = precision_score(y_true, y_pred_classes)\n",
        "recall = recall_score(y_true, y_pred_classes)\n",
        "f1 = f1_score(y_true, y_pred_classes)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# Confusion Matrix function\n",
        "def plot_confusion_matrix(y_true, y_pred_classes):\n",
        "    cm = confusion_matrix(y_true, y_pred_classes)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Shoplifting'], yticklabels=['Normal', 'Shoplifting'])\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plot_confusion_matrix(y_true, y_pred_classes)\n",
        "\n"
      ],
      "metadata": {
        "id": "DNnp6v5A7S-R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}