{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPN4gHI7g3opcuoj1oE/EKm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4zue7CYyYwtM"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tensorflow.keras.applications import MobileNetV3Small\n","from tensorflow.keras.layers import GRU, Dense, BatchNormalization, Flatten, TimeDistributed, GlobalAveragePooling2D\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc\n","import time\n","import pickle\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n","\n","from google.colab import drive"]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"id":"0KlLJXQYboy0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["DATASET_PATH = '/content/drive/My Drive/Shoplifting-Datasets/Shoplifting-Dataset-Merged-Balanced'\n","SEQUENCE_LENGTH = 30\n","FRAME_SIZE = (224, 224)\n","OUTPUT_PATH = '/content/drive/My Drive/Shoplifting-Datasets/preprocessed_data'\n","\n","os.makedirs(OUTPUT_PATH, exist_ok=True)\n","\n","# uniformly sample frames\n","def uniform_sampling(frames, num_samples):\n","    indices = np.linspace(0, len(frames) - 1, num_samples, dtype=int)\n","    return [frames[i] for i in indices]\n","\n","# pad frames if a video is too short\n","def pad_frames(frames, num_samples):\n","    while len(frames) < num_samples:\n","        frames.append(frames[-1])\n","    return frames[:num_samples]\n","\n","# preprocess a single video\n","def preprocess_video(video_path, sequence_length, frame_size):\n","    cap = cv2.VideoCapture(video_path)\n","    frames = []\n","\n","    # Extract all frames\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert to RGB\n","        frame = cv2.resize(frame, frame_size)  # Resize to target size\n","        frames.append(frame)\n","\n","    cap.release()\n","\n","    # Handle short or long videos\n","    if len(frames) >= sequence_length:\n","        frames = uniform_sampling(frames, sequence_length)\n","    else:\n","        frames = pad_frames(frames, sequence_length)\n","\n","    # Normalize pixel values to [0, 1]\n","    frames = [frame / 255.0 for frame in frames]\n","    return np.array(frames)\n","\n","# process and save the dataset incrementally\n","def process_and_save_dataset(dataset_path, sequence_length, frame_size, output_path):\n","    class_names = ['Normal', 'Shoplifting']\n","\n","    for label, class_name in enumerate(class_names):\n","        class_path = os.path.join(dataset_path, class_name)\n","        for video_file in os.listdir(class_path):\n","            video_path = os.path.join(class_path, video_file)\n","            if not video_file.endswith(('.mp4', '.avi', '.mov', '.mkv')):\n","                continue\n","\n","            try:\n","                # Preprocess the original video\n","                frames = preprocess_video(video_path, sequence_length, frame_size)\n","                video_data = [(frames, label)]\n","\n","                # Save processed video incrementally\n","                for idx, (processed_frames, processed_label) in enumerate(video_data):\n","                    save_path = os.path.join(output_path, f\"{class_name}_{video_file}_{idx}.pkl\")\n","                    with open(save_path, 'wb') as file:\n","                        pickle.dump((processed_frames, processed_label), file)\n","\n","            except Exception as e:\n","                print(f\"Error processing video {video_path}: {e}\")\n","\n","\n","print(\"Processing and saving dataset...\")\n","process_and_save_dataset(DATASET_PATH, SEQUENCE_LENGTH, FRAME_SIZE, OUTPUT_PATH)\n","print(\"Dataset processing complete!\")\n","\n","\n","\n"],"metadata":{"id":"NHM-UcveY_XX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","OUTPUT_PATH = '/content/drive/My Drive/Shoplifting-Datasets/preprocessed_data'\n","\n","# Count the number of files in the directory\n","num_files = len([f for f in os.listdir(OUTPUT_PATH) if os.path.isfile(os.path.join(OUTPUT_PATH, f))])\n","\n","print(f\"Total number of files in the folder: {num_files}\")\n","\n"],"metadata":{"id":"5RRJhw1LLSxX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["OUTPUT_PATH = '/content/drive/My Drive/Shoplifting-Datasets/preprocessed_data'\n","\n","# Load and split the dataset into train, validation, and test sets\n","def load_and_split_dataset(output_path):\n","    data = []\n","    labels = []\n","\n","    for file in os.listdir(output_path):\n","        file_path = os.path.join(output_path, file)\n","        with open(file_path, 'rb') as f:\n","            frames, label = pickle.load(f)\n","            data.append(frames)\n","            labels.append(label)\n","\n","    data = np.array(data)\n","    labels = np.array(labels)\n","\n","    X_train, X_temp, y_train, y_temp = train_test_split(data, labels, test_size=0.2, random_state=42, stratify=labels)\n","    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n","\n","\n","\n","    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n","\n","\n","print(\"Loading and splitting dataset...\")\n","(X_train, y_train), (X_val, y_val), (X_test, y_test) = load_and_split_dataset(OUTPUT_PATH)\n","print(\"Loading and splitting dataset copmleted\")\n","# Print data shapes\n","print(f\"Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}\")\n","print(f\"Validation data shape: {X_val.shape}, Validation labels shape: {y_val.shape}\")\n","print(f\"Test data shape: {X_test.shape}, Test labels shape: {y_test.shape}\")"],"metadata":{"id":"ZCwZWM-NmjFq","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","def save_data(data, file_name):\n","    with open(file_name, 'wb') as file:\n","        pickle.dump(data, file)\n","\n","\n","drive_save_path = '/content/drive/My Drive/Shoplifting-Datasets/processed_data_no_augmentation_splited801010'\n","\n","import os\n","if not os.path.exists(drive_save_path):\n","    os.makedirs(drive_save_path)\n","\n","\n","print(\"Saving processed and splitted data...\")\n","save_data((X_train, y_train), os.path.join(drive_save_path, f'train_data_{SEQUENCE_LENGTH}.pkl'))\n","save_data((X_val, y_val), os.path.join(drive_save_path, f'val_data_{SEQUENCE_LENGTH}.pkl'))\n","save_data((X_test, y_test), os.path.join(drive_save_path, f'test_data_{SEQUENCE_LENGTH}.pkl'))\n","\n","print(\"Data saving complete!\")\n"],"metadata":{"id":"nAnf8tYFdeQy"},"execution_count":null,"outputs":[]}]}